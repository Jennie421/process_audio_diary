#!/bin/bash
#BSUB -J BLSViz
#BSUB -o /data/sbdp/logs/audio_diary/output-log-bls-viz-%J.out
#BSUB -e /data/sbdp/logs/audio_diary/error-log-bls-viz-%J.err

# Submit job as follows:
# ---
# bsub < viz_queue.lsf
# ---

#BSUB -q normal
#BSUB -n 2
#BSUB -R rusage[mem=4000]

# SETTINGS TO CHANGE!
bash_home_path=/PHShome/me741/.bashrc # path to bashrc or bash_profile for current user
repo_root=/PHShome/me741/process_audio_diary # path to the repository folder for current user
# make sure conda environment for process_audio is set up before running this!

# Some important variables to check (Can be removed later)
echo '---PROCESS RESOURCE LIMITS---'
ulimit -a
echo '---SHARED LIBRARY PATH---'
echo $LD_LIBRARY_PATH
echo '---APPLICATION SEARCH PATH:---'
echo $PATH
echo '---LSF Parameters:---'
printenv | grep '^LSF'
echo '---LSB Parameters:---'
printenv | grep '^LSB'
echo '---LOADED MODULES:---'
module list
echo '---SHELL:---'
echo $SHELL
echo '---HOSTNAME:---'
hostname
echo '---GROUP MEMBERSHIP (files are created in the first group listed):---'
groups
echo '---DEFAULT FILE PERMISSIONS (UMASK):---'
umask
echo '---CURRENT WORKING DIRECTORY:---'
pwd
echo '---DISK SPACE QUOTA---'
df .
echo '---TEMPORARY SCRATCH FOLDER ($TMPDIR):---'
echo $TMPDIR

source /etc/profile.d/modules.sh
source "$bash_home_path"
module load anaconda
source activate audio_process

# in this instance likely just keeping study as BLS
study=BLS
export study
export repo_root

# log that script is starting
echo "Beginning script - diary visualization generation for:"
echo "$study"
echo ""

# add current time for runtime tracking purposes
now=$(date +"%T")
echo "Current time: ${now}"
echo ""

# start with distributions - per patient and for the overall study
# feature distributions (OpenSMILE and NLP) also generated here
echo "Generating QC and feature distributions with histograms" 
bash "$repo_root"/individual_modules/run_distribution_plots.sh
echo ""

# add current time for runtime tracking purposes
now=$(date +"%T")
echo "Current time: ${now}"
echo ""

# create heatmaps to see progression of select audio and transcript QC features over time per patient (each diary one block)
echo "Generating QC heatmaps for each patient"
bash "$repo_root"/individual_modules/run_heatmap_plots.sh
echo ""

# add current time for runtime tracking purposes
now=$(date +"%T")
echo "Current time: ${now}"
echo ""

# sentiment-colored wordclouds for the transcripts (if any new)
echo "Generating sentiment-colored wordclouds for each available transcript"
bash "$repo_root"/individual_modules/run_wordclouds.sh
echo ""

# add current time for runtime tracking purposes
now=$(date +"%T")
echo "Current time: ${now}"
echo ""

# finally do correlation matrices for the study-wide distributions
# since no need to loop over patients here or do any other bash preprocessing, just call python script directly
echo "Creating study-wide correlation matrices"
python "$repo_root"/individual_modules/functions_called/phone_diary_correlations.py "$study"
echo ""

# add current time for runtime tracking purposes
now=$(date +"%T")
echo "Current time: ${now}"
echo ""

# script wrap up
echo "Script completed"
